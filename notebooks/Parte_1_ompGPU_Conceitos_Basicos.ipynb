{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBbK2dQW3QYd"
      },
      "source": [
        "# Programe sua GPU com OpenMP\n",
        "\n",
        "Autores:\n",
        "_Hermes Senger_ e\n",
        "_Jaime Freire de Souza_\n",
        "\n",
        "Data de criação:     16/04/2022   \n",
        "Última modificação:     \n",
        "\n",
        "    24/04/2024 - Ajustado para usar o cuda 12 que ja vem pré-instalado no colab\n",
        "\n",
        "## Configuração do ambiente\n",
        "\n",
        "Precisaremos de um compilador capaz de gerar código executável para GPUs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "q3og1sYm1n51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbab0a33-bde5-4c92-d4ab-20c5e1709bc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'/usr/local/cuda' -> '/usr/local/cuda-12.2'\n",
            "--2024-04-24 19:58:03--  https://openmp-course.s3.amazonaws.com/llvm.tar.gz\n",
            "Resolving openmp-course.s3.amazonaws.com (openmp-course.s3.amazonaws.com)... 3.5.20.164, 52.217.131.41, 52.216.178.99, ...\n",
            "Connecting to openmp-course.s3.amazonaws.com (openmp-course.s3.amazonaws.com)|3.5.20.164|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 810538565 (773M) [application/x-gzip]\n",
            "Saving to: ‘llvm.tar.gz’\n",
            "\n",
            "llvm.tar.gz         100%[===================>] 772.99M  32.5MB/s    in 25s     \n",
            "\n",
            "2024-04-24 19:58:28 (31.5 MB/s) - ‘llvm.tar.gz’ saved [810538565/810538565]\n",
            "\n",
            "  ------------  Terminou a instalação! Pode continuar  ------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "%%shell\n",
        "ln -sfnv /usr/local/cuda-12.2 /usr/local/cuda\n",
        "pip install -q matplotlib numpy\n",
        "wget https://openmp-course.s3.amazonaws.com/llvm.tar.gz\n",
        "tar -xzvf llvm.tar.gz >/dev/null 2>&1\n",
        "echo \"  ------------  Terminou a instalação! Pode continuar  ------------------\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVhiiS6J6Oq6"
      },
      "source": [
        "\n",
        "Também é preciso informar a localização de bibliotecas e executáveis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lhrUpNNi7ken"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ['LLVM_PATH'] = '/content/llvm'\n",
        "os.environ['PATH'] = os.environ['LLVM_PATH'] + '/bin:' + os.environ['PATH']\n",
        "os.environ['LD_LIBRARY_PATH'] = os.environ['LLVM_PATH'] + '/lib:' + os.environ['LD_LIBRARY_PATH']\n",
        "os.environ['TSAN_OPTIONS'] = 'ignore_noninstrumented_modules=1'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkhWQSVHjmXP"
      },
      "source": [
        "\n",
        "Agora poderemos testar se nosso ambiente de programação está funcionando como esperado\n",
        "."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "q1SdNZkf1y3h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "772a55e2-e24b-4b63-bca9-d53088d14e49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing test.c\n"
          ]
        }
      ],
      "source": [
        "%%writefile test.c\n",
        "\n",
        "#include <omp.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "int main() {\n",
        "  int num_devices = omp_get_num_devices();\n",
        "  printf(\"Temos %d devices alocados\\n\", num_devices);\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -la /usr/local"
      ],
      "metadata": {
        "id": "KHTp0mmEg3G7",
        "outputId": "58a53118-57e4-4529-8fe4-22f9d5adab56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 72\n",
            "drwxr-xr-x 1 root root 4096 Apr 24 19:57 .\n",
            "drwxr-xr-x 1 root root 4096 Apr 24 19:56 ..\n",
            "drwxr-xr-x 1 root root 4096 Apr 23 13:40 bin\n",
            "drwxr-xr-x 3 root root 4096 Apr 23 13:40 colab\n",
            "lrwxrwxrwx 1 root root   20 Apr 24 19:57 cuda -> /usr/local/cuda-12.2\n",
            "lrwxrwxrwx 1 root root   25 Nov 10 04:57 cuda-12 -> /etc/alternatives/cuda-12\n",
            "drwxr-xr-x 1 root root 4096 Nov 10 05:10 cuda-12.2\n",
            "drwxr-xr-x 1 root root 4096 Apr 23 13:35 etc\n",
            "drwxr-xr-x 2 root root 4096 Oct  4  2023 games\n",
            "drwxr-xr-x 2 root root 4096 Apr 23 13:33 _gcs_config_ops.so\n",
            "drwxr-xr-x 1 root root 4096 Apr 23 13:35 include\n",
            "drwxr-xr-x 1 root root 4096 Apr 23 13:34 lib\n",
            "drwxr-xr-x 3 root root 4096 Apr 23 13:35 lib64\n",
            "drwxr-xr-x 3 root root 4096 Apr 23 13:34 licensing\n",
            "lrwxrwxrwx 1 root root    9 Oct  4  2023 man -> share/man\n",
            "drwxr-xr-x 2 root root 4096 Oct  4  2023 sbin\n",
            "drwxr-xr-x 1 root root 4096 Apr 23 13:37 share\n",
            "drwxr-xr-x 2 root root 4096 Oct  4  2023 src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85hpozN-6Oq8"
      },
      "source": [
        "\n",
        "A seguir, vamos compilar e executar o programa criado. Usaremos sempre o compilador __clang__, que utiliza o backend __llvm__, que gera código executável para GPUs de diferentes tipos e modelos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "d1nutgLC2FNu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60729550-000b-4125-8fb9-371d46afc541"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clang-13: \u001b[0;1;35mwarning: \u001b[0m\u001b[1mUnknown CUDA version. cuda.h: CUDA_VERSION=12020. Assuming the latest supported version 10.1 [-Wunknown-cuda-version]\u001b[0m\n",
            "Temos 1 devices alocados\n"
          ]
        }
      ],
      "source": [
        "#%%shell\n",
        "\n",
        "!clang -fopenmp -fopenmp-targets=nvptx64-nvidia-cuda -Xopenmp-target -march=sm_75 test.c -o teste\n",
        "\n",
        "!./teste"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnWo2aV_jzyC"
      },
      "source": [
        "Vamos verificar o modelo de GPU alocada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EkDZeg8ej01I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acd60cba-27bd-4204-b596-9289a0e15d2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Apr 24 19:58:58 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n",
            "Architecture:            x86_64\n",
            "  CPU op-mode(s):        32-bit, 64-bit\n",
            "  Address sizes:         46 bits physical, 48 bits virtual\n",
            "  Byte Order:            Little Endian\n",
            "CPU(s):                  2\n",
            "  On-line CPU(s) list:   0,1\n",
            "Vendor ID:               GenuineIntel\n",
            "  Model name:            Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "    CPU family:          6\n",
            "    Model:               85\n",
            "    Thread(s) per core:  2\n",
            "    Core(s) per socket:  1\n",
            "    Socket(s):           1\n",
            "    Stepping:            3\n",
            "    BogoMIPS:            4000.29\n",
            "    Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clf\n",
            "                         lush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_\n",
            "                         good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fm\n",
            "                         a cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hyp\n",
            "                         ervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsb\n",
            "                         ase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512d\n",
            "                         q rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsave\n",
            "                         c xgetbv1 xsaves arat md_clear arch_capabilities\n",
            "Virtualization features: \n",
            "  Hypervisor vendor:     KVM\n",
            "  Virtualization type:   full\n",
            "Caches (sum of all):     \n",
            "  L1d:                   32 KiB (1 instance)\n",
            "  L1i:                   32 KiB (1 instance)\n",
            "  L2:                    1 MiB (1 instance)\n",
            "  L3:                    38.5 MiB (1 instance)\n",
            "NUMA:                    \n",
            "  NUMA node(s):          1\n",
            "  NUMA node0 CPU(s):     0,1\n",
            "Vulnerabilities:         \n",
            "  Gather data sampling:  Not affected\n",
            "  Itlb multihit:         Not affected\n",
            "  L1tf:                  Mitigation; PTE Inversion\n",
            "  Mds:                   Vulnerable; SMT Host state unknown\n",
            "  Meltdown:              Vulnerable\n",
            "  Mmio stale data:       Vulnerable\n",
            "  Retbleed:              Vulnerable\n",
            "  Spec rstack overflow:  Not affected\n",
            "  Spec store bypass:     Vulnerable\n",
            "  Spectre v1:            Vulnerable: __user pointer sanitization and usercopy barriers only; no swap\n",
            "                         gs barriers\n",
            "  Spectre v2:            Vulnerable, IBPB: disabled, STIBP: disabled, PBRSB-eIBRS: Not affected\n",
            "  Srbds:                 Not affected\n",
            "  Tsx async abort:       Vulnerable\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n",
        "!lscpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Meg61W0NkC_I"
      },
      "source": [
        "## Exempo 1: Calculo de Pi - serial na CPU\n",
        "\n",
        "O programa a seguir calcula o valos re Pi pelo método de integração numérica. Esta primeira versão trabalha de forma serial, somente na CPU. Nas próximas versões, nós faremos melhorias nesse programa para acelerar o seu desempenho.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Gi0URNZWzQR0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "471c1fb7-65db-4db2-80c4-99a2eded7ded"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing ex1-pi_serial.c\n"
          ]
        }
      ],
      "source": [
        "%%writefile ex1-pi_serial.c\n",
        "// The OpenMP Common Core - pg. 58\n",
        "// https://github.com/tgmattso/OmpCommonCore/blob/master/Book/C/Fig_4.5_poprogseq.c\n",
        "#include <stdio.h>\n",
        "#include <omp.h>\n",
        "static long num_steps = 100000000;\n",
        "double step;\n",
        "int main ()\n",
        "{\n",
        "   int i;\n",
        "   double x, pi, sum = 0.0;\n",
        "   double start_time, run_time;\n",
        "\n",
        "   step = 1.0 / (double) num_steps;\n",
        "\n",
        "   start_time = omp_get_wtime();\n",
        "\n",
        "   for (i = 0; i < num_steps; i++){\n",
        "      x = (i + 0.5) * step;\n",
        "      sum += 4.0 / (1.0 + x * x);\n",
        "   }\n",
        "\n",
        "   pi = step * sum;\n",
        "   run_time = omp_get_wtime() - start_time;\n",
        "   printf(\"pi = \\%lf, \\%ld steps, \\%lf secs\\n \",\n",
        "                pi, num_steps, run_time);\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "HEyI-Dd5whKn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "926d2003-fae4-4fc0-b7ae-d2d360448c47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clang-13: \u001b[0;1;35mwarning: \u001b[0m\u001b[1mUnknown CUDA version. cuda.h: CUDA_VERSION=12020. Assuming the latest supported version 10.1 [-Wunknown-cuda-version]\u001b[0m\n",
            "pi = 3.141593, 100000000 steps, 1.473295 secs\n",
            " "
          ]
        }
      ],
      "source": [
        "#%%shell\n",
        "\n",
        "!clang -fopenmp -fopenmp-targets=nvptx64-nvidia-cuda -Xopenmp-target -march=sm_75 ex1-pi_serial.c -o ex1-pi_serial\n",
        "\n",
        "!./ex1-pi_serial"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obs.: O compilador clang emite um warning sobre uma versão de cuda desconhecida. Isso ocorre poque esse clang foi compilado em uma versão anterior de cuda. Pode ser ignorada."
      ],
      "metadata": {
        "id": "sRUq4sR4sPUp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILOriiruzKD5"
      },
      "source": [
        "## Exemplo 2: Pi paralelo na CPU - Pi-V1.0.c\n",
        "\n",
        "O próximo exemplo mostra uma forma de paralelizar o algoritmo para execução em CPU, utilizando os seguintes recursos do OpenMP:\n",
        "\n",
        "* Regiões paralelas\n",
        "* Loops paralelos\n",
        "* Redução"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZuyMcdbuv70m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fd4f975-deb1-435a-a677-d4752c1474f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing Pi-V1.0.c\n"
          ]
        }
      ],
      "source": [
        "%%writefile Pi-V1.0.c\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <omp.h>\n",
        "static long num_steps = 100000000;\n",
        "double step;\n",
        "int main ()\n",
        "{\n",
        "   int i;\n",
        "   double x, pi, sum = 0.0;\n",
        "   double start_time, run_time;\n",
        "\n",
        "   step = 1.0 / (double) num_steps;\n",
        "\n",
        "   start_time = omp_get_wtime();\n",
        "   #pragma omp parallel\n",
        "   {\n",
        "     double x; /* cada thread terá sua variavel x local */\n",
        "     #pragma omp for reduction(+:sum)\n",
        "       for (i = 0; i < num_steps; i++){\n",
        "          x = (i + 0.5) * step;\n",
        "          sum += 4.0 / (1.0 + x * x);\n",
        "       }\n",
        "   }\n",
        "   pi = step * sum;\n",
        "   run_time = omp_get_wtime() - start_time;\n",
        "   printf(\"   pi = \\%20.15lf, \\%ld steps, \\%lf secs\\n\", pi,\n",
        "          num_steps, run_time);\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Os compiladores implementam diversas otimizações durante a geração de código. Veremos a seguir, como essas otimizações podem acelerar nosso código.\n",
        "Para mais detalhes sobre os flags, veja aqui:\n",
        "https://clang.llvm.org/docs/CommandGuide/clang.html\n"
      ],
      "metadata": {
        "id": "ULa1t8ZccwO3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "S-fhnR0I3Oml",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afde55a8-8b18-4709-fd7a-f1cfca37f9b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   pi =    3.141592653589910, 100000000 steps, 1.433680 secs\n",
            "   pi =    3.141592653589910, 100000000 steps, 0.292215 secs\n",
            "   pi =    3.141592653589910, 100000000 steps, 0.279505 secs\n",
            "   pi =    3.141592653589910, 100000000 steps, 0.165115 secs\n",
            "Architecture:            x86_64\n",
            "  CPU op-mode(s):        32-bit, 64-bit\n",
            "  Address sizes:         46 bits physical, 48 bits virtual\n",
            "  Byte Order:            Little Endian\n",
            "CPU(s):                  2\n",
            "  On-line CPU(s) list:   0,1\n",
            "Vendor ID:               GenuineIntel\n",
            "  Model name:            Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "    CPU family:          6\n",
            "    Model:               85\n",
            "    Thread(s) per core:  2\n",
            "    Core(s) per socket:  1\n",
            "    Socket(s):           1\n",
            "    Stepping:            3\n",
            "    BogoMIPS:            4000.29\n",
            "    Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clf\n",
            "                         lush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_\n",
            "                         good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fm\n",
            "                         a cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hyp\n",
            "                         ervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsb\n",
            "                         ase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512d\n",
            "                         q rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsave\n",
            "                         c xgetbv1 xsaves arat md_clear arch_capabilities\n",
            "Virtualization features: \n",
            "  Hypervisor vendor:     KVM\n",
            "  Virtualization type:   full\n",
            "Caches (sum of all):     \n",
            "  L1d:                   32 KiB (1 instance)\n",
            "  L1i:                   32 KiB (1 instance)\n",
            "  L2:                    1 MiB (1 instance)\n",
            "  L3:                    38.5 MiB (1 instance)\n",
            "NUMA:                    \n",
            "  NUMA node(s):          1\n",
            "  NUMA node0 CPU(s):     0,1\n",
            "Vulnerabilities:         \n",
            "  Gather data sampling:  Not affected\n",
            "  Itlb multihit:         Not affected\n",
            "  L1tf:                  Mitigation; PTE Inversion\n",
            "  Mds:                   Vulnerable; SMT Host state unknown\n",
            "  Meltdown:              Vulnerable\n",
            "  Mmio stale data:       Vulnerable\n",
            "  Retbleed:              Vulnerable\n",
            "  Spec rstack overflow:  Not affected\n",
            "  Spec store bypass:     Vulnerable\n",
            "  Spectre v1:            Vulnerable: __user pointer sanitization and usercopy barriers only; no swap\n",
            "                         gs barriers\n",
            "  Spectre v2:            Vulnerable, IBPB: disabled, STIBP: disabled, PBRSB-eIBRS: Not affected\n",
            "  Srbds:                 Not affected\n",
            "  Tsx async abort:       Vulnerable\n"
          ]
        }
      ],
      "source": [
        "#%%shell\n",
        "\n",
        "#!clang -fopenmp -fopenmp-targets=nvptx64-nvidia-cuda Pi-V1.0.c -o Pi-V1.0\n",
        "!clang -fopenmp Pi-V1.0.c -o Pi-V1.0\n",
        "!./Pi-V1.0\n",
        "!clang -O1 -fopenmp Pi-V1.0.c -o Pi-V1.0\n",
        "!./Pi-V1.0\n",
        "!clang -O2 -fopenmp Pi-V1.0.c -o Pi-V1.0\n",
        "!./Pi-V1.0\n",
        "!clang -O3 -fopenmp Pi-V1.0.c -o Pi-V1.0\n",
        "!./Pi-V1.0\n",
        "!lscpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9VPB5yp6Oq_"
      },
      "source": [
        "# Exercício 1 - Soma de vetores\n",
        "\n",
        "O exercício a seguir utiliza a cláusula __map__ para fazer a movimentação correta dos dados entre o host e o device. Sigas os passos:\n",
        "1. Paralelize a soma de vetores com a diretiva `#pragma omp target` para executar na GPU\n",
        "2. Paralelize o loop da inicialização na CPU com `#pragma omp parallel for`\n",
        "3. Paralelizar o loop de teste na CPU. \\\\\n",
        "Obs.: Você pode utilizar redução para totalizar a contagem de erros:\n",
        "`#pragma omp parallel for reduction(+:err)`\n",
        "4. O programa está disponível aqui, caso precise restaurá-lo:\n",
        "https://github.com/UoB-HPC/openmp-tutorial/blob/master/vadd.c\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "H-IMRGuS6Oq_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b93deb9-13c3-43d1-f782-7d83a45e0c1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing soma-vetores.c\n"
          ]
        }
      ],
      "source": [
        "%%writefile soma-vetores.c\n",
        "\n",
        "// Copie aqui o código ...\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <omp.h>\n",
        "#define N 100000\n",
        "#define TOL  0.0000001\n",
        "//\n",
        "//  This is a simple program to add two vectors\n",
        "//  and verify the results.\n",
        "//\n",
        "//  History: Written by Tim Mattson, November 2017\n",
        "//\n",
        "int main()\n",
        "{\n",
        "\n",
        "    float a[N], b[N], c[N], res[N];\n",
        "    int err=0;\n",
        "\n",
        "   // fill the arrays\n",
        "   for (int i=0; i<N; i++){\n",
        "      a[i] = (float)i;\n",
        "      b[i] = 2.0*(float)i;\n",
        "      c[i] = 0.0;\n",
        "      res[i] = i + 2*i;\n",
        "   }\n",
        "\n",
        "   // add two vectors\n",
        "   for (int i=0; i<N; i++){\n",
        "      c[i] = a[i] + b[i];\n",
        "   }\n",
        "\n",
        "   // test results\n",
        "   for(int i=0;i<N;i++){\n",
        "      float val = c[i] - res[i];\n",
        "      val = val*val;\n",
        "      if(val>TOL) err++;\n",
        "   }\n",
        "\n",
        "   printf(\" Os vetores foram somados com %d erros!\\n\",err);\n",
        "   return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "W5nIsf4-6OrA",
        "outputId": "edd4493c-c635-4a6a-a1d8-9e10c0208ca6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clang-13: \u001b[0;1;35mwarning: \u001b[0m\u001b[1mUnknown CUDA version. cuda.h: CUDA_VERSION=12020. Assuming the latest supported version 10.1 [-Wunknown-cuda-version]\u001b[0m\n",
            " Os vetores foram somados com 0 erros!\n"
          ]
        }
      ],
      "source": [
        "#%%shell\n",
        "\n",
        "#!clang -fopenmp -fopenmp-targets=nvptx64-nvidia-cuda Pi-V1.0.c -o Pi-V1.0\n",
        "!clang -fopenmp -fopenmp-targets=nvptx64-nvidia-cuda -Xopenmp-target -march=sm_75 soma-vetores.c -o soma-vetores\n",
        "!./soma-vetores\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwtwGT-M6OrA"
      },
      "source": [
        "\n",
        "## Exercício 2: Movimentação explícita de dados - Soma de vetores na GPU\n",
        "\n",
        "Agora vamos alocar os vetores no heap em vez do stack:\n",
        "* O programa abaixo trocou `double a[N]`\n",
        "* por `*a = malloc(sizeof(double) * N)`\n",
        "* Use a diretiva target para descarregar a execução na GPU\n",
        "`#pragma omp targtet`\n",
        "* Copie os dados dos arrays no heap para/da GPU com as cláusulas map\n",
        "`map(tofrom:… ), map(to:…), map(from:…)`\n",
        "\n",
        "__Obs.:__ O código base da próxima célula foi retirado daqui, caso precise restaurá-lo: https://github.com/UoB-HPC/openmp-tutorial/blob/master/vadd_heap.c  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-G13Nmtv6OrA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0926f561-633d-4cc9-c224-eb024b999291"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing vadd_heap.c\n"
          ]
        }
      ],
      "source": [
        "%%writefile vadd_heap.c\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <omp.h>\n",
        "#define N 100000\n",
        "#define TOL  0.0000001\n",
        "//\n",
        "//  This is a simple program to add two vectors\n",
        "//  and verify the results.\n",
        "//\n",
        "//  History: Written by Tim Mattson, November 2017\n",
        "//\n",
        "int main()\n",
        "{\n",
        "\n",
        "    float *a   = malloc(sizeof(float) * N);\n",
        "    float *b   = malloc(sizeof(float) * N);\n",
        "    float *c   = malloc(sizeof(float) * N);\n",
        "    float *res = malloc(sizeof(float) * N);\n",
        "    int err=0;\n",
        "\n",
        "   // fill the arrays\n",
        "   for (int i=0; i<N; i++){\n",
        "      a[i] = (float)i;\n",
        "      b[i] = 2.0*(float)i;\n",
        "      c[i] = 0.0;\n",
        "      res[i] = i + 2*i;\n",
        "   }\n",
        "\n",
        "   // add two vectors\n",
        "   for (int i=0; i<N; i++){\n",
        "      c[i] = a[i] + b[i];\n",
        "   }\n",
        "\n",
        "   // test results\n",
        "   for(int i=0;i<N;i++){\n",
        "      float val = c[i] - res[i];\n",
        "      val = val*val;\n",
        "      if(val>TOL) err++;\n",
        "   }\n",
        "   printf(\" vectors added with %d errors\\n\",err);\n",
        "\n",
        "   free(a);\n",
        "   free(b);\n",
        "   free(c);\n",
        "   free(res);\n",
        "\n",
        "   return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "by2oCYUJ6OrA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dc44f15-322d-4461-c376-dc62080a341b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clang-13: \u001b[0;1;35mwarning: \u001b[0m\u001b[1mUnknown CUDA version. cuda.h: CUDA_VERSION=12020. Assuming the latest supported version 10.1 [-Wunknown-cuda-version]\u001b[0m\n",
            " vectors added with 0 errors\n"
          ]
        }
      ],
      "source": [
        "#%%shell\n",
        "\n",
        "#!clang -fopenmp -fopenmp-targets=nvptx64-nvidia-cuda Pi-V1.0.c -o Pi-V1.0\n",
        "!clang -fopenmp -fopenmp-targets=nvptx64-nvidia-cuda -Xopenmp-target -march=sm_75 vadd_heap.c -o vadd_heap\n",
        "!./vadd_heap\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DR-K26ae_QVw"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7a6iFUxkQFr"
      },
      "source": [
        "# Exemplo 3 - Pi  V2.0 - threads na GPU\n",
        "\n",
        "A seguir, vamos utilizar a GPU para tentar acelerar nosso programa, utilizando:\n",
        "* Construção __target__ :\n",
        "\n",
        "  `#pragma omp target`    \n",
        "  `#pragma omp parallel for`   \n",
        "  `     for (i=0;i<N;i++) ...`\n",
        "\n",
        "  Modifique o programa abaixo, introduzindo a melhoria sugerida:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "L4I4VPkMze5-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d90c2ca-1c70-4646-eaea-f749cd4cc9c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing Pi-par-V2.c\n"
          ]
        }
      ],
      "source": [
        "%%writefile Pi-par-V2.c\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <omp.h>\n",
        "static long num_steps = 100000000;\n",
        "double step;\n",
        "int main ()\n",
        "{\n",
        "   int i;\n",
        "   double x, pi, sum = 0.0;\n",
        "   double start_time, run_time;\n",
        "\n",
        "   step = 1.0 / (double) num_steps;\n",
        "\n",
        "   start_time = omp_get_wtime();\n",
        "\n",
        "   // Criar uma região paralela no device\n",
        "\n",
        "   {\n",
        "     // Fazer o worksharing\n",
        "\n",
        "     for (i = 0; i < num_steps; i++){\n",
        "       x = (i + 0.5) * step;\n",
        "       sum += 4.0 / (1.0 + x * x);\n",
        "      }\n",
        "   }\n",
        "\n",
        "   pi = step * sum;\n",
        "   run_time = omp_get_wtime() - start_time;\n",
        "   printf(\"pi = \\%lf, \\%ld steps, \\%lf secs\\n \",\n",
        "                pi, num_steps, run_time);\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "O3xUrwYj0GUE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f756cc9-181f-4352-bea0-cb9e2eb58094"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clang-13: \u001b[0;1;35mwarning: \u001b[0m\u001b[1mUnknown CUDA version. cuda.h: CUDA_VERSION=12020. Assuming the latest supported version 10.1 [-Wunknown-cuda-version]\u001b[0m\n",
            "pi = 3.141593, 100000000 steps, 1.512842 secs\n",
            " "
          ]
        }
      ],
      "source": [
        "#%%shell\n",
        "\n",
        "!clang -fopenmp -fopenmp-targets=nvptx64-nvidia-cuda -Xopenmp-target -march=sm_75 Pi-par-V2.c -o Pi-par-V2\n",
        "\n",
        "!./Pi-par-V2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYszYHwyHpUZ"
      },
      "source": [
        "\n",
        "__Pergunta:__ O que aconteceu? Compare o tempo de execução com o da CPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYwp_hxXJ_h9"
      },
      "source": [
        "__Resposta__:  Nesta versão, somente __um time de threads__ foi criado, para executar blocos de iterações do loop. Os threads desse time executarão de forma paralela, mas ocupando apenas um __compute unit__ apenas, o resultado não será muito bom.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8WeyznxGiEg"
      },
      "source": [
        "# Exemplo 4 - Pi V3.0 - múltiplos times\n",
        "\n",
        "A seguir, vamos utilizar a GPU para tentar acelerar nosso programa, utilizando:\n",
        "* Construções __target__, __teams__ e __distribute__ :\n",
        "\n",
        "  `#pragma omp target`    \n",
        "  `#pragma omp teams`    \n",
        "  `#pragma omp distribute`    \n",
        "  `     for (i=0;i<N;i++) ...`\n",
        "\n",
        "\n",
        "  Modifique o programa abaixo, introduzindo a melhoria sugerida.\n",
        "\n",
        "  __Obs:__\n",
        "  Para este exercício, não utilize a construção  `#pragma omp parallel for`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Jh8a5Qt_2ES5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c970bf0-42ba-479f-9ac8-72a479dc2733"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing Pi-par-V3.c\n"
          ]
        }
      ],
      "source": [
        "%%writefile Pi-par-V3.c\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <omp.h>\n",
        "static long num_steps = 1000000; //100000000\n",
        "double step;\n",
        "int main ()\n",
        "{\n",
        "   int i;\n",
        "   double x, pi, sum = 0.0;\n",
        "   double start_time, run_time;\n",
        "\n",
        "   step = 1.0 / (double) num_steps;\n",
        "\n",
        "   start_time = omp_get_wtime();\n",
        "   #pragma omp target map(sum)\n",
        "   #pragma omp teams reduction(+: sum)\n",
        "    {\n",
        "     double x;\n",
        "     #pragma omp distribute\n",
        "     for (i = 0; i < num_steps; i++){\n",
        "       x = (i + 0.5) * step;\n",
        "       sum += 4.0 / (1.0 + x * x);\n",
        "     }\n",
        "   }\n",
        "\n",
        "   pi = step * sum;\n",
        "   run_time = omp_get_wtime() - start_time;\n",
        "   printf(\"pi = \\%lf, \\%ld steps, \\%lf secs\\n \",\n",
        "                pi, num_steps, run_time);\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "H4zpaSmzJ3Ej",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf89d5dd-c547-4076-c27b-d478ca383ac9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clang-13: \u001b[0;1;35mwarning: \u001b[0m\u001b[1mUnknown CUDA version. cuda.h: CUDA_VERSION=12020. Assuming the latest supported version 10.1 [-Wunknown-cuda-version]\u001b[0m\n",
            "pi = 3.141593, 1000000 steps, 1.642667 secs\n",
            " "
          ]
        }
      ],
      "source": [
        "#%%shell\n",
        "\n",
        "#!clang -O3 -fopenmp -fopenmp-targets=nvptx64-nvidia-cuda -Xopenmp-target -march=sm_37 pi-par-V3.c -o pi-par-V3\n",
        "!clang -fopenmp -fopenmp-targets=nvptx64 -Xopenmp-target -march=sm_75 Pi-par-V3.c -o Pi-par-V3\n",
        "\n",
        "!./Pi-par-V3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZlO9E026OrC"
      },
      "source": [
        "Compare o tempo de execução com o anterior e explique por que foi mais lento que o anterior."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aA0WEYwS6OrC"
      },
      "source": [
        "__Resposta__: Neste exemplo, foram criados 128 teams (depende do compilador/hardware) com apenas 1 thread (chamado de thread inicial) para cada team."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEpSayKC6OrC"
      },
      "source": [
        "# Exemplo 5 - Pi V4.0 - times+threads+SIMD\n",
        "\n",
        "A seguir, vamos utilizar utilizar paralelismo em 3 níveis: times, threads nos times, e SIMD nos threads para acelerar nosso programa:\n",
        "\n",
        "  __`#pragma omp target`__    \n",
        "  __`#pragma omp teams distribute`__  \n",
        "    `for (i=0;i<N;i++) ...`    \n",
        "  __`#pragma omp parallel for simd`__  \n",
        "    `for (i=0;i<M;i++) ...`\n",
        "     \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "T0jAUPbt6OrC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87ef20d8-0a77-4a51-e91b-d4efa0c17397"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing Pi-par-V4.c\n"
          ]
        }
      ],
      "source": [
        "%%writefile Pi-par-V4.c\n",
        "\n",
        "#define MIN(x, y) (((x) < (y)) ? (x) : (y))\n",
        "#include <stdio.h>\n",
        "#include <omp.h>\n",
        "static long num_steps = 100000000;\n",
        "double step;\n",
        "int main ()\n",
        "{\n",
        "   int i;\n",
        "   double x, pi, sum = 0.0;\n",
        "   double start_time, run_time;\n",
        "\n",
        "   step = 1.0 / (double) num_steps;\n",
        "\n",
        "   start_time = omp_get_wtime();\n",
        "   #pragma omp target map(sum)\n",
        "   #pragma omp teams reduction(+:sum)\n",
        "   {\n",
        "     int block_size = num_steps/omp_get_num_teams();\n",
        "//     #pragma omp distribute dist_sched(static, 1)\n",
        "     #pragma omp distribute\n",
        "     for (int ii = 0; ii < num_steps; ii += block_size){\n",
        "         #pragma omp parallel for simd reduction(+: sum)\n",
        "//         #pragma omp parallel for reduction(+: sum)\n",
        "         for (int i = ii; i < MIN(ii+block_size, num_steps); i++) {\n",
        "             x = (i + 0.5) * step;\n",
        "             sum += 4.0 / (1.0 + x * x);\n",
        "         }\n",
        "     }\n",
        "   }\n",
        "\n",
        "   pi = step * sum;\n",
        "   run_time = omp_get_wtime() - start_time;\n",
        "   printf(\"pi = \\%lf, \\%ld steps, \\%lf secs\\n \",\n",
        "                pi, num_steps, run_time);\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "uWF3s_E_6OrD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ddc7043-c326-4885-d6c6-ff66ecf3f95d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clang-13: \u001b[0;1;35mwarning: \u001b[0m\u001b[1mUnknown CUDA version. cuda.h: CUDA_VERSION=12020. Assuming the latest supported version 10.1 [-Wunknown-cuda-version]\u001b[0m\n",
            "pi = 3.141593, 100000000 steps, 0.133658 secs\n",
            " "
          ]
        }
      ],
      "source": [
        "#%%shell\n",
        "\n",
        "#!clang -O3 -fopenmp -fopenmp-targets=nvptx64-nvidia-cuda -Xopenmp-target -march=sm_37 pi-par-V3.c -o pi-par-V3\n",
        "!clang  -fopenmp -fopenmp-targets=nvptx64 -Xopenmp-target -march=sm_75 Pi-par-V4.c -o Pi-par-V4\n",
        "\n",
        "!./Pi-par-V4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2-1bt706OrD"
      },
      "source": [
        "# Extra 1- Pi V5.0\n",
        "\n",
        "A seguir, vamos utilizar a GPU para tentar acelerar nosso programa, utilizando:\n",
        "* Construções __teams distribute__ , __parallel for simd__:\n",
        "\n",
        "  `#pragma omp target`    \n",
        "  `#pragma omp teams distribute`   \n",
        "  `for (i=0;i<N;i++) ...`   \n",
        "  `#pragma omp parallel for`   \n",
        "    `for (i=0;i<block_sizeN;i++) ...`\n",
        "     \n",
        "\n",
        "Modifique o programa abaixo, introduzindo a melhoria sugerida.\n",
        "\n",
        "...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "EWSHoc8h6OrD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91df20b2-0bbf-4b98-b761-c07ced583b1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing Pi-par-V5.c\n"
          ]
        }
      ],
      "source": [
        "%%writefile Pi-par-V5.c\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <omp.h>\n",
        "static long num_steps = 100000000;\n",
        "double step;\n",
        "int main ()\n",
        "{\n",
        "   int i;\n",
        "   double x, pi, sum = 0.0;\n",
        "   double start_time, run_time;\n",
        "\n",
        "   step = 1.0 / (double) num_steps;\n",
        "\n",
        "   start_time = omp_get_wtime();\n",
        "   #pragma omp target map(sum)\n",
        "   {\n",
        "     #pragma omp teams distribute parallel for reduction(+:sum) private(x)\n",
        "     for (i = 0; i < num_steps; i++){\n",
        "       x = (i + 0.5) * step;\n",
        "       sum += 4.0 / (1.0 + x * x);\n",
        "     }\n",
        "   }\n",
        "\n",
        "   pi = step * sum;\n",
        "   run_time = omp_get_wtime() - start_time;\n",
        "   printf(\"pi = \\%lf, \\%ld steps, \\%lf secs\\n \",\n",
        "                pi, num_steps, run_time);\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "D4d9XZkW6OrD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fc66291-13c7-4682-e4d9-490df82784de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clang-13: \u001b[0;1;35mwarning: \u001b[0m\u001b[1mUnknown CUDA version. cuda.h: CUDA_VERSION=12020. Assuming the latest supported version 10.1 [-Wunknown-cuda-version]\u001b[0m\n",
            "pi = 3.141593, 100000000 steps, 1.466733 secs\n",
            " "
          ]
        }
      ],
      "source": [
        "#%%shell\n",
        "\n",
        "!clang -fopenmp -fopenmp-targets=nvptx64 -Xopenmp-target -march=sm_75 Pi-par-V5.c -o Pi-par-V5\n",
        "\n",
        "!./Pi-par-V5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eVLMZIy6OrD"
      },
      "source": [
        "# Extra 2 - Pi V6.0\n",
        "\n",
        "Juntando tudo isso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "y_7ct4aL6OrD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6bcf736-dcdb-484d-b6db-6a2378285f20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing Pi-par-V6.c\n"
          ]
        }
      ],
      "source": [
        "%%writefile Pi-par-V6.c\n",
        "#define MIN(x, y) (((x) < (y)) ? (x) : (y))\n",
        "#include <stdio.h>\n",
        "#include <omp.h>\n",
        "static long num_steps = 100000000;\n",
        "double step;\n",
        "int main ()\n",
        "{\n",
        "   int i;\n",
        "   double x, pi, sum = 0.0;\n",
        "   double start_time, run_time;\n",
        "\n",
        "   step = 1.0 / (double) num_steps;\n",
        "   start_time = omp_get_wtime();\n",
        "   #pragma omp target map(sum)\n",
        "//   #pragma omp teams distribute parallel for simd reduction(+: sum) private(x)\n",
        "   #pragma omp teams distribute parallel for reduction(+: sum) private(x)\n",
        "   for (i=0; i< num_steps; i++){\n",
        "             x = (i + 0.5) * step;\n",
        "             sum += 4.0 / (1.0 + x * x);\n",
        "   }\n",
        "   pi = step * sum;\n",
        "   run_time = omp_get_wtime() - start_time;\n",
        "   printf(\"pi = \\%lf, \\%ld steps, \\%lf secs\\n \",\n",
        "                pi, num_steps, run_time);\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "3etWJGlh6OrE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbd9243b-52a3-4e09-cddf-1e4310a1a779"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clang-13: \u001b[0;1;35mwarning: \u001b[0m\u001b[1mUnknown CUDA version. cuda.h: CUDA_VERSION=12020. Assuming the latest supported version 10.1 [-Wunknown-cuda-version]\u001b[0m\n",
            "pi = 3.141593, 100000000 steps, 1.462093 secs\n",
            " "
          ]
        }
      ],
      "source": [
        "#%%shell\n",
        "\n",
        "!clang -fopenmp -fopenmp-targets=nvptx64 -Xopenmp-target -march=sm_75 Pi-par-V6.c -o Pi-par-V6\n",
        "\n",
        "!./Pi-par-V6"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}