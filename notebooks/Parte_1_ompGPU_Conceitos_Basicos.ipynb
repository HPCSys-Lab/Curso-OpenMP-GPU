{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBbK2dQW3QYd"
      },
      "source": [
        "# Programe sua GPU com OpenMP\n",
        "\n",
        "Autores:\n",
        "_Hermes Senger_ e\n",
        "_Jaime Freire de Souza_\n",
        "\n",
        "Data de criação:     16/04/2022   \n",
        "Última modificação:     \n",
        "\n",
        "## Configuração do ambiente\n",
        "\n",
        "Precisaremos de um compilador capaz de gerar código executável para GPUs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "q3og1sYm1n51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d09434a4-2453-4fad-94b3-0bb35961b63d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'/usr/local/cuda' -> '/usr/local/cuda-11/'\n",
            "--2023-07-17 01:17:01--  https://openmp-course.s3.amazonaws.com/llvm.tar.gz\n",
            "Resolving openmp-course.s3.amazonaws.com (openmp-course.s3.amazonaws.com)... 52.216.42.33, 3.5.6.124, 3.5.27.170, ...\n",
            "Connecting to openmp-course.s3.amazonaws.com (openmp-course.s3.amazonaws.com)|52.216.42.33|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 810538565 (773M) [application/x-gzip]\n",
            "Saving to: ‘llvm.tar.gz’\n",
            "\n",
            "llvm.tar.gz         100%[===================>] 772.99M  33.5MB/s    in 24s     \n",
            "\n",
            "2023-07-17 01:17:25 (32.6 MB/s) - ‘llvm.tar.gz’ saved [810538565/810538565]\n",
            "\n",
            "  ------------  Terminou a instalação! Pode continuar  ------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "%%shell\n",
        "ln -sfnv /usr/local/cuda-11/ /usr/local/cuda\n",
        "pip install -q matplotlib numpy\n",
        "wget https://openmp-course.s3.amazonaws.com/llvm.tar.gz\n",
        "tar -xzvf llvm.tar.gz >/dev/null 2>&1\n",
        "echo \"  ------------  Terminou a instalação! Pode continuar  ------------------\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVhiiS6J6Oq6"
      },
      "source": [
        "\n",
        "Também é preciso informar a localização de bibliotecas e executáveis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lhrUpNNi7ken"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ['LLVM_PATH'] = '/content/llvm'\n",
        "os.environ['PATH'] = os.environ['LLVM_PATH'] + '/bin:' + os.environ['PATH']\n",
        "os.environ['LD_LIBRARY_PATH'] = os.environ['LLVM_PATH'] + '/lib:' + os.environ['LD_LIBRARY_PATH']\n",
        "os.environ['TSAN_OPTIONS'] = 'ignore_noninstrumented_modules=1'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkhWQSVHjmXP"
      },
      "source": [
        "\n",
        "Agora poderemos testar se nosso ambiente de programação está funcionando como esperado\n",
        "."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "q1SdNZkf1y3h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fb506c3-8409-4154-cc25-72835cf465ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing test.c\n"
          ]
        }
      ],
      "source": [
        "%%writefile test.c\n",
        "\n",
        "#include <omp.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "int main() {\n",
        "  int num_devices = omp_get_num_devices();\n",
        "  printf(\"Temos %d devices alocados\\n\", num_devices);\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85hpozN-6Oq8"
      },
      "source": [
        "\n",
        "A seguir, vamos compilar e executar o programa criado. Usaremos sempre o compilador __clang__, que utiliza o backend __llvm__, que gera código executável para GPUs de diferentes tipos e modelos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "d1nutgLC2FNu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0792887c-bfc7-46b6-8efc-e0c536a06fdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clang-13: \u001b[0;1;35mwarning: \u001b[0m\u001b[1mUnknown CUDA version. cuda.h: CUDA_VERSION=11080. Assuming the latest supported version 10.1 [-Wunknown-cuda-version]\u001b[0m\n",
            "Temos 1 devices alocados\n"
          ]
        }
      ],
      "source": [
        "#%%shell\n",
        "\n",
        "!clang -fopenmp -fopenmp-targets=nvptx64-nvidia-cuda -Xopenmp-target -march=sm_75 test.c -o teste\n",
        "\n",
        "!./teste"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnWo2aV_jzyC"
      },
      "source": [
        "Vamos verificar o modelo de GPU alocada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "EkDZeg8ej01I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c7b2ba8-4c48-4d64-feac-596bcf1e1439"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jul 17 01:19:46 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "Architecture:                    x86_64\n",
            "CPU op-mode(s):                  32-bit, 64-bit\n",
            "Byte Order:                      Little Endian\n",
            "Address sizes:                   46 bits physical, 48 bits virtual\n",
            "CPU(s):                          2\n",
            "On-line CPU(s) list:             0,1\n",
            "Thread(s) per core:              2\n",
            "Core(s) per socket:              1\n",
            "Socket(s):                       1\n",
            "NUMA node(s):                    1\n",
            "Vendor ID:                       GenuineIntel\n",
            "CPU family:                      6\n",
            "Model:                           85\n",
            "Model name:                      Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "Stepping:                        3\n",
            "CPU MHz:                         2000.138\n",
            "BogoMIPS:                        4000.27\n",
            "Hypervisor vendor:               KVM\n",
            "Virtualization type:             full\n",
            "L1d cache:                       32 KiB\n",
            "L1i cache:                       32 KiB\n",
            "L2 cache:                        1 MiB\n",
            "L3 cache:                        38.5 MiB\n",
            "NUMA node0 CPU(s):               0,1\n",
            "Vulnerability Itlb multihit:     Not affected\n",
            "Vulnerability L1tf:              Mitigation; PTE Inversion\n",
            "Vulnerability Mds:               Vulnerable; SMT Host state unknown\n",
            "Vulnerability Meltdown:          Vulnerable\n",
            "Vulnerability Mmio stale data:   Vulnerable\n",
            "Vulnerability Retbleed:          Vulnerable\n",
            "Vulnerability Spec store bypass: Vulnerable\n",
            "Vulnerability Spectre v1:        Vulnerable: __user pointer sanitization and use\n",
            "                                 rcopy barriers only; no swapgs barriers\n",
            "Vulnerability Spectre v2:        Vulnerable, IBPB: disabled, STIBP: disabled, PB\n",
            "                                 RSB-eIBRS: Not affected\n",
            "Vulnerability Srbds:             Not affected\n",
            "Vulnerability Tsx async abort:   Vulnerable\n",
            "Flags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtr\n",
            "                                 r pge mca cmov pat pse36 clflush mmx fxsr sse s\n",
            "                                 se2 ss ht syscall nx pdpe1gb rdtscp lm constant\n",
            "                                 _tsc rep_good nopl xtopology nonstop_tsc cpuid \n",
            "                                 tsc_known_freq pni pclmulqdq ssse3 fma cx16 pci\n",
            "                                 d sse4_1 sse4_2 x2apic movbe popcnt aes xsave a\n",
            "                                 vx f16c rdrand hypervisor lahf_lm abm 3dnowpref\n",
            "                                 etch invpcid_single ssbd ibrs ibpb stibp fsgsba\n",
            "                                 se tsc_adjust bmi1 hle avx2 smep bmi2 erms invp\n",
            "                                 cid rtm mpx avx512f avx512dq rdseed adx smap cl\n",
            "                                 flushopt clwb avx512cd avx512bw avx512vl xsaveo\n",
            "                                 pt xsavec xgetbv1 xsaves arat md_clear arch_cap\n",
            "                                 abilities\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n",
        "!lscpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Meg61W0NkC_I"
      },
      "source": [
        "## Exempo 1: Calculo de Pi - serial na CPU\n",
        "\n",
        "O programa a seguir calcula o valos re Pi pelo método de integração numérica. Esta primeira versão trabalha de forma serial, somente na CPU. Nas próximas versões, nós faremos melhorias nesse programa para acelerar o seu desempenho.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Gi0URNZWzQR0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7886e840-0d2f-430a-e262-f1ce51a92e52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing ex1-pi_serial.c\n"
          ]
        }
      ],
      "source": [
        "%%writefile ex1-pi_serial.c\n",
        "// The OpenMP Common Core - pg. 58\n",
        "// https://github.com/tgmattso/OmpCommonCore/blob/master/Book/C/Fig_4.5_poprogseq.c\n",
        "#include <stdio.h>\n",
        "#include <omp.h>\n",
        "static long num_steps = 100000000;\n",
        "double step;\n",
        "int main ()\n",
        "{\n",
        "   int i;\n",
        "   double x, pi, sum = 0.0;\n",
        "   double start_time, run_time;\n",
        "\n",
        "   step = 1.0 / (double) num_steps;\n",
        "\n",
        "   start_time = omp_get_wtime();\n",
        "\n",
        "   for (i = 0; i < num_steps; i++){\n",
        "      x = (i + 0.5) * step;\n",
        "      sum += 4.0 / (1.0 + x * x);\n",
        "   }\n",
        "\n",
        "   pi = step * sum;\n",
        "   run_time = omp_get_wtime() - start_time;\n",
        "   printf(\"pi = \\%lf, \\%ld steps, \\%lf secs\\n \",\n",
        "                pi, num_steps, run_time);\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HEyI-Dd5whKn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9b092c1-29a5-4384-9da8-53339c33e2aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clang-13: \u001b[0;1;35mwarning: \u001b[0m\u001b[1mUnknown CUDA version. cuda.h: CUDA_VERSION=11080. Assuming the latest supported version 10.1 [-Wunknown-cuda-version]\u001b[0m\n",
            "pi = 3.141593, 100000000 steps, 1.417067 secs\n",
            " "
          ]
        }
      ],
      "source": [
        "#%%shell\n",
        "\n",
        "!clang -fopenmp -fopenmp-targets=nvptx64-nvidia-cuda -Xopenmp-target -march=sm_75 ex1-pi_serial.c -o ex1-pi_serial\n",
        "\n",
        "!./ex1-pi_serial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILOriiruzKD5"
      },
      "source": [
        "## Exemplo 2: Pi paralelo na CPU - Pi-V1.0.c\n",
        "\n",
        "O próximo exemplo mostra uma forma de paralelizar o algoritmo para execução em CPU, utilizando os seguintes recursos do OpenMP:\n",
        "\n",
        "* Regiões paralelas\n",
        "* Loops paralelos\n",
        "* Redução"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ZuyMcdbuv70m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ac37781-3de5-40f6-be3d-2bb4f514f9d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing Pi-V1.0.c\n"
          ]
        }
      ],
      "source": [
        "%%writefile Pi-V1.0.c\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <omp.h>\n",
        "static long num_steps = 100000000;\n",
        "double step;\n",
        "int main ()\n",
        "{\n",
        "   int i;\n",
        "   double x, pi, sum = 0.0;\n",
        "   double start_time, run_time;\n",
        "\n",
        "   step = 1.0 / (double) num_steps;\n",
        "\n",
        "   start_time = omp_get_wtime();\n",
        "   #pragma omp parallel\n",
        "   {\n",
        "     double x; /* cada thread terá sua variavel x local */\n",
        "     #pragma omp for reduction(+:sum)\n",
        "       for (i = 0; i < num_steps; i++){\n",
        "          x = (i + 0.5) * step;\n",
        "          sum += 4.0 / (1.0 + x * x);\n",
        "       }\n",
        "   }\n",
        "   pi = step * sum;\n",
        "   run_time = omp_get_wtime() - start_time;\n",
        "   printf(\"   pi = \\%20.15lf, \\%ld steps, \\%lf secs\\n\", pi,\n",
        "          num_steps, run_time);\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Os compiladores implementam diversas otimizações durante a geração de código. Veremos a seguir, como essas otimizações podem acelerar nosso código.\n",
        "Para mais detalhes sobre os flags, veja aqui:\n",
        "https://clang.llvm.org/docs/CommandGuide/clang.html\n"
      ],
      "metadata": {
        "id": "ULa1t8ZccwO3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "S-fhnR0I3Oml",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3b59a73-cc80-4aed-c040-285263480f7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   pi =    3.141592653589910, 100000000 steps, 0.712020 secs\n",
            "   pi =    3.141592653589910, 100000000 steps, 0.155057 secs\n",
            "   pi =    3.141592653589910, 100000000 steps, 0.145885 secs\n",
            "   pi =    3.141592653589910, 100000000 steps, 0.141715 secs\n",
            "Architecture:                    x86_64\n",
            "CPU op-mode(s):                  32-bit, 64-bit\n",
            "Byte Order:                      Little Endian\n",
            "Address sizes:                   46 bits physical, 48 bits virtual\n",
            "CPU(s):                          2\n",
            "On-line CPU(s) list:             0,1\n",
            "Thread(s) per core:              2\n",
            "Core(s) per socket:              1\n",
            "Socket(s):                       1\n",
            "NUMA node(s):                    1\n",
            "Vendor ID:                       GenuineIntel\n",
            "CPU family:                      6\n",
            "Model:                           85\n",
            "Model name:                      Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "Stepping:                        3\n",
            "CPU MHz:                         2000.138\n",
            "BogoMIPS:                        4000.27\n",
            "Hypervisor vendor:               KVM\n",
            "Virtualization type:             full\n",
            "L1d cache:                       32 KiB\n",
            "L1i cache:                       32 KiB\n",
            "L2 cache:                        1 MiB\n",
            "L3 cache:                        38.5 MiB\n",
            "NUMA node0 CPU(s):               0,1\n",
            "Vulnerability Itlb multihit:     Not affected\n",
            "Vulnerability L1tf:              Mitigation; PTE Inversion\n",
            "Vulnerability Mds:               Vulnerable; SMT Host state unknown\n",
            "Vulnerability Meltdown:          Vulnerable\n",
            "Vulnerability Mmio stale data:   Vulnerable\n",
            "Vulnerability Retbleed:          Vulnerable\n",
            "Vulnerability Spec store bypass: Vulnerable\n",
            "Vulnerability Spectre v1:        Vulnerable: __user pointer sanitization and use\n",
            "                                 rcopy barriers only; no swapgs barriers\n",
            "Vulnerability Spectre v2:        Vulnerable, IBPB: disabled, STIBP: disabled, PB\n",
            "                                 RSB-eIBRS: Not affected\n",
            "Vulnerability Srbds:             Not affected\n",
            "Vulnerability Tsx async abort:   Vulnerable\n",
            "Flags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtr\n",
            "                                 r pge mca cmov pat pse36 clflush mmx fxsr sse s\n",
            "                                 se2 ss ht syscall nx pdpe1gb rdtscp lm constant\n",
            "                                 _tsc rep_good nopl xtopology nonstop_tsc cpuid \n",
            "                                 tsc_known_freq pni pclmulqdq ssse3 fma cx16 pci\n",
            "                                 d sse4_1 sse4_2 x2apic movbe popcnt aes xsave a\n",
            "                                 vx f16c rdrand hypervisor lahf_lm abm 3dnowpref\n",
            "                                 etch invpcid_single ssbd ibrs ibpb stibp fsgsba\n",
            "                                 se tsc_adjust bmi1 hle avx2 smep bmi2 erms invp\n",
            "                                 cid rtm mpx avx512f avx512dq rdseed adx smap cl\n",
            "                                 flushopt clwb avx512cd avx512bw avx512vl xsaveo\n",
            "                                 pt xsavec xgetbv1 xsaves arat md_clear arch_cap\n",
            "                                 abilities\n"
          ]
        }
      ],
      "source": [
        "#%%shell\n",
        "\n",
        "#!clang -fopenmp -fopenmp-targets=nvptx64-nvidia-cuda Pi-V1.0.c -o Pi-V1.0\n",
        "!clang -fopenmp Pi-V1.0.c -o Pi-V1.0\n",
        "!./Pi-V1.0\n",
        "!clang -O1 -fopenmp Pi-V1.0.c -o Pi-V1.0\n",
        "!./Pi-V1.0\n",
        "!clang -O2 -fopenmp Pi-V1.0.c -o Pi-V1.0\n",
        "!./Pi-V1.0\n",
        "!clang -O3 -fopenmp Pi-V1.0.c -o Pi-V1.0\n",
        "!./Pi-V1.0\n",
        "!lscpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9VPB5yp6Oq_"
      },
      "source": [
        "# Exercício 1 - Soma de vetores\n",
        "\n",
        "O exercício a seguir utiliza a cláusula __map__ para fazer a movimentação correta dos dados entre o host e o device. Sigas os passos:\n",
        "1. Paralelize a soma de vetores com a diretiva `#pragma omp target` para executar na GPU\n",
        "2. Paralelize o loop da inicialização na CPU com `#pragma omp parallel for`\n",
        "3. Paralelizar o loop de teste na CPU. \\\\\n",
        "Obs.: Você pode utilizar redução para totalizar a contagem de erros:\n",
        "`#pragma omp parallel for reduction(+:err)`\n",
        "4. O programa está disponível aqui, caso precise restaurá-lo:\n",
        "https://github.com/UoB-HPC/openmp-tutorial/blob/master/vadd.c\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "H-IMRGuS6Oq_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c55a329a-9cee-4989-f843-4f29342ec5db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing soma-vetores.c\n"
          ]
        }
      ],
      "source": [
        "%%writefile soma-vetores.c\n",
        "\n",
        "// Copie aqui o código ...\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <omp.h>\n",
        "#define N 100000\n",
        "#define TOL  0.0000001\n",
        "//\n",
        "//  This is a simple program to add two vectors\n",
        "//  and verify the results.\n",
        "//\n",
        "//  History: Written by Tim Mattson, November 2017\n",
        "//\n",
        "int main()\n",
        "{\n",
        "\n",
        "    float a[N], b[N], c[N], res[N];\n",
        "    int err=0;\n",
        "\n",
        "   // fill the arrays\n",
        "   for (int i=0; i<N; i++){\n",
        "      a[i] = (float)i;\n",
        "      b[i] = 2.0*(float)i;\n",
        "      c[i] = 0.0;\n",
        "      res[i] = i + 2*i;\n",
        "   }\n",
        "\n",
        "   // add two vectors\n",
        "   for (int i=0; i<N; i++){\n",
        "      c[i] = a[i] + b[i];\n",
        "   }\n",
        "\n",
        "   // test results\n",
        "   for(int i=0;i<N;i++){\n",
        "      float val = c[i] - res[i];\n",
        "      val = val*val;\n",
        "      if(val>TOL) err++;\n",
        "   }\n",
        "\n",
        "   printf(\" Os vetores foram somados com %d erros!\\n\",err);\n",
        "   return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5nIsf4-6OrA"
      },
      "outputs": [],
      "source": [
        "#%%shell\n",
        "\n",
        "#!clang -fopenmp -fopenmp-targets=nvptx64-nvidia-cuda Pi-V1.0.c -o Pi-V1.0\n",
        "!clang -fopenmp -fopenmp-targets=nvptx64-nvidia-cuda -Xopenmp-target -march=sm_75 soma-vetores.c -o soma-vetores\n",
        "!./soma-vetores\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwtwGT-M6OrA"
      },
      "source": [
        "\n",
        "## Exercício 2: Movimentação explícita de dados - Soma de vetores na GPU\n",
        "\n",
        "Agora vamos alocar os vetores no heap em vez do stack:\n",
        "* O programa abaixo trocou `double a[N]`\n",
        "* por `*a = malloc(sizeof(double) * N)`\n",
        "* Use a diretiva target para descarregar a execução na GPU\n",
        "`#pragma omp targtet`\n",
        "* Copie os dados dos arrays no heap para/da GPU com as cláusulas map\n",
        "`map(tofrom:… ), map(to:…), map(from:…)`\n",
        "\n",
        "__Obs.:__ O código base da próxima célula foi retirado daqui, caso precise restaurá-lo: https://github.com/UoB-HPC/openmp-tutorial/blob/master/vadd_heap.c  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "-G13Nmtv6OrA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9829b1c8-61ab-4174-a7dd-f4d560eaf3a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing vadd_heap.c\n"
          ]
        }
      ],
      "source": [
        "%%writefile vadd_heap.c\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <omp.h>\n",
        "#define N 100000\n",
        "#define TOL  0.0000001\n",
        "//\n",
        "//  This is a simple program to add two vectors\n",
        "//  and verify the results.\n",
        "//\n",
        "//  History: Written by Tim Mattson, November 2017\n",
        "//\n",
        "int main()\n",
        "{\n",
        "\n",
        "    float *a   = malloc(sizeof(float) * N);\n",
        "    float *b   = malloc(sizeof(float) * N);\n",
        "    float *c   = malloc(sizeof(float) * N);\n",
        "    float *res = malloc(sizeof(float) * N);\n",
        "    int err=0;\n",
        "\n",
        "   // fill the arrays\n",
        "   for (int i=0; i<N; i++){\n",
        "      a[i] = (float)i;\n",
        "      b[i] = 2.0*(float)i;\n",
        "      c[i] = 0.0;\n",
        "      res[i] = i + 2*i;\n",
        "   }\n",
        "\n",
        "   // add two vectors\n",
        "   for (int i=0; i<N; i++){\n",
        "      c[i] = a[i] + b[i];\n",
        "   }\n",
        "\n",
        "   // test results\n",
        "   for(int i=0;i<N;i++){\n",
        "      float val = c[i] - res[i];\n",
        "      val = val*val;\n",
        "      if(val>TOL) err++;\n",
        "   }\n",
        "   printf(\" vectors added with %d errors\\n\",err);\n",
        "\n",
        "   free(a);\n",
        "   free(b);\n",
        "   free(c);\n",
        "   free(res);\n",
        "\n",
        "   return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "by2oCYUJ6OrA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dd7be0b-bcac-498b-95c1-820456201eba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clang-13: \u001b[0;1;35mwarning: \u001b[0m\u001b[1mUnknown CUDA version. cuda.h: CUDA_VERSION=11080. Assuming the latest supported version 10.1 [-Wunknown-cuda-version]\u001b[0m\n",
            " vectors added with 0 errors\n"
          ]
        }
      ],
      "source": [
        "#%%shell\n",
        "\n",
        "#!clang -fopenmp -fopenmp-targets=nvptx64-nvidia-cuda Pi-V1.0.c -o Pi-V1.0\n",
        "!clang -fopenmp -fopenmp-targets=nvptx64-nvidia-cuda -Xopenmp-target -march=sm_75 vadd_heap.c -o vadd_heap\n",
        "!./vadd_heap\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DR-K26ae_QVw"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7a6iFUxkQFr"
      },
      "source": [
        "# Exemplo 3 - Pi  V2.0 - threads na GPU\n",
        "\n",
        "A seguir, vamos utilizar a GPU para tentar acelerar nosso programa, utilizando:\n",
        "* Construção __target__ :\n",
        "\n",
        "  `#pragma omp target`    \n",
        "  `#pragma omp parallel for`   \n",
        "  `     for (i=0;i<N;i++) ...`\n",
        "\n",
        "  Modifique o programa abaixo, introduzindo a melhoria sugerida:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "L4I4VPkMze5-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cf61c94-b462-4ae3-93b6-ad3dcd41c768"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing Pi-par-V2.c\n"
          ]
        }
      ],
      "source": [
        "%%writefile Pi-par-V2.c\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <omp.h>\n",
        "static long num_steps = 100000000;\n",
        "double step;\n",
        "int main ()\n",
        "{\n",
        "   int i;\n",
        "   double x, pi, sum = 0.0;\n",
        "   double start_time, run_time;\n",
        "\n",
        "   step = 1.0 / (double) num_steps;\n",
        "\n",
        "   start_time = omp_get_wtime();\n",
        "\n",
        "   // Criar uma região paralela no device\n",
        "\n",
        "   {\n",
        "     // Fazer o worksharing\n",
        "\n",
        "     for (i = 0; i < num_steps; i++){\n",
        "       x = (i + 0.5) * step;\n",
        "       sum += 4.0 / (1.0 + x * x);\n",
        "      }\n",
        "   }\n",
        "\n",
        "   pi = step * sum;\n",
        "   run_time = omp_get_wtime() - start_time;\n",
        "   printf(\"pi = \\%lf, \\%ld steps, \\%lf secs\\n \",\n",
        "                pi, num_steps, run_time);\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "O3xUrwYj0GUE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "911cb4d2-fce6-4782-871c-8a3660183b28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clang-13: \u001b[0;1;35mwarning: \u001b[0m\u001b[1mUnknown CUDA version. cuda.h: CUDA_VERSION=11080. Assuming the latest supported version 10.1 [-Wunknown-cuda-version]\u001b[0m\n",
            "pi = 3.141593, 100000000 steps, 1.369899 secs\n",
            " "
          ]
        }
      ],
      "source": [
        "#%%shell\n",
        "\n",
        "!clang -fopenmp -fopenmp-targets=nvptx64-nvidia-cuda -Xopenmp-target -march=sm_75 Pi-par-V2.c -o Pi-par-V2\n",
        "\n",
        "!./Pi-par-V2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYszYHwyHpUZ"
      },
      "source": [
        "\n",
        "__Pergunta:__ O que aconteceu? Compare o tempo de execução com o da CPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYwp_hxXJ_h9"
      },
      "source": [
        "__Resposta__:  Nesta versão, somente __um time de threads__ foi criado, para executar blocos de iterações do loop. Os threads desse time executarão de forma paralela, mas ocupando apenas um __compute unit__ apenas, o resultado não será muito bom.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8WeyznxGiEg"
      },
      "source": [
        "# Exemplo 4 - Pi V3.0 - múltiplos times\n",
        "\n",
        "A seguir, vamos utilizar a GPU para tentar acelerar nosso programa, utilizando:\n",
        "* Construções __target__, __teams__ e __distribute__ :\n",
        "\n",
        "  `#pragma omp target`    \n",
        "  `#pragma omp teams`    \n",
        "  `#pragma omp distribute`    \n",
        "  `     for (i=0;i<N;i++) ...`\n",
        "\n",
        "\n",
        "  Modifique o programa abaixo, introduzindo a melhoria sugerida.\n",
        "\n",
        "  __Obs:__\n",
        "  Para este exercício, não utilize a construção  `#pragma omp parallel for`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Jh8a5Qt_2ES5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3588496-48a7-4785-885a-ea2ca7130697"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing Pi-par-V3.c\n"
          ]
        }
      ],
      "source": [
        "%%writefile Pi-par-V3.c\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <omp.h>\n",
        "static long num_steps = 1000000; //100000000\n",
        "double step;\n",
        "int main ()\n",
        "{\n",
        "   int i;\n",
        "   double x, pi, sum = 0.0;\n",
        "   double start_time, run_time;\n",
        "\n",
        "   step = 1.0 / (double) num_steps;\n",
        "\n",
        "   start_time = omp_get_wtime();\n",
        "   #pragma omp target map(sum)\n",
        "   #pragma omp teams reduction(+: sum)\n",
        "    {\n",
        "     double x;\n",
        "     #pragma omp distribute\n",
        "     for (i = 0; i < num_steps; i++){\n",
        "       x = (i + 0.5) * step;\n",
        "       sum += 4.0 / (1.0 + x * x);\n",
        "     }\n",
        "   }\n",
        "\n",
        "   pi = step * sum;\n",
        "   run_time = omp_get_wtime() - start_time;\n",
        "   printf(\"pi = \\%lf, \\%ld steps, \\%lf secs\\n \",\n",
        "                pi, num_steps, run_time);\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "H4zpaSmzJ3Ej",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c340255d-b99c-4df8-8538-f8267e70d16d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clang-13: \u001b[0;1;35mwarning: \u001b[0m\u001b[1mUnknown CUDA version. cuda.h: CUDA_VERSION=11080. Assuming the latest supported version 10.1 [-Wunknown-cuda-version]\u001b[0m\n",
            "pi = 3.141593, 1000000 steps, 1.593711 secs\n",
            " "
          ]
        }
      ],
      "source": [
        "#%%shell\n",
        "\n",
        "#!clang -O3 -fopenmp -fopenmp-targets=nvptx64-nvidia-cuda -Xopenmp-target -march=sm_37 pi-par-V3.c -o pi-par-V3\n",
        "!clang -fopenmp -fopenmp-targets=nvptx64 -Xopenmp-target -march=sm_75 Pi-par-V3.c -o Pi-par-V3\n",
        "\n",
        "!./Pi-par-V3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZlO9E026OrC"
      },
      "source": [
        "Compare o tempo de execução com o anterior e explique por que foi mais lento que o anterior."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aA0WEYwS6OrC"
      },
      "source": [
        "__Resposta__: Neste exemplo, foram criados 128 teams (depende do compilador/hardware) com apenas 1 thread (chamado de thread inicial) para cada team."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEpSayKC6OrC"
      },
      "source": [
        "# Exemplo 5 - Pi V4.0 - times+threads+SIMD\n",
        "\n",
        "A seguir, vamos utilizar utilizar paralelismo em 3 níveis: times, threads nos times, e SIMD nos threads para acelerar nosso programa:\n",
        "\n",
        "  __`#pragma omp target`__    \n",
        "  __`#pragma omp teams distribute`__  \n",
        "    `for (i=0;i<N;i++) ...`    \n",
        "  __`#pragma omp parallel for simd`__  \n",
        "    `for (i=0;i<M;i++) ...`\n",
        "     \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0jAUPbt6OrC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a5438ba-036f-4b80-f5e8-f4432c23e7a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing Pi-par-V4.c\n"
          ]
        }
      ],
      "source": [
        "%%writefile Pi-par-V4.c\n",
        "\n",
        "#define MIN(x, y) (((x) < (y)) ? (x) : (y))\n",
        "#include <stdio.h>\n",
        "#include <omp.h>\n",
        "static long num_steps = 100000000;\n",
        "double step;\n",
        "int main ()\n",
        "{\n",
        "   int i;\n",
        "   double x, pi, sum = 0.0;\n",
        "   double start_time, run_time;\n",
        "\n",
        "   step = 1.0 / (double) num_steps;\n",
        "\n",
        "   start_time = omp_get_wtime();\n",
        "   #pragma omp target map(sum)\n",
        "   #pragma omp teams reduction(+:sum)\n",
        "   {\n",
        "     int block_size = num_steps/omp_get_num_teams();\n",
        "//     #pragma omp distribute dist_sched(static, 1)\n",
        "     #pragma omp distribute\n",
        "     for (int ii = 0; ii < num_steps; ii += block_size){\n",
        "         #pragma omp parallel for simd reduction(+: sum)\n",
        "//         #pragma omp parallel for reduction(+: sum)\n",
        "         for (int i = ii; i < MIN(ii+block_size, num_steps); i++) {\n",
        "             x = (i + 0.5) * step;\n",
        "             sum += 4.0 / (1.0 + x * x);\n",
        "         }\n",
        "     }\n",
        "   }\n",
        "\n",
        "   pi = step * sum;\n",
        "   run_time = omp_get_wtime() - start_time;\n",
        "   printf(\"pi = \\%lf, \\%ld steps, \\%lf secs\\n \",\n",
        "                pi, num_steps, run_time);\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWF3s_E_6OrD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bde64728-0be1-4764-a8b9-24df1ea68fb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clang-13: \u001b[0;1;35mwarning: \u001b[0m\u001b[1mUnknown CUDA version. cuda.h: CUDA_VERSION=11080. Assuming the latest supported version 10.1 [-Wunknown-cuda-version]\u001b[0m\n",
            "pi = 3.141593, 100000000 steps, 0.336792 secs\n",
            " "
          ]
        }
      ],
      "source": [
        "#%%shell\n",
        "\n",
        "#!clang -O3 -fopenmp -fopenmp-targets=nvptx64-nvidia-cuda -Xopenmp-target -march=sm_37 pi-par-V3.c -o pi-par-V3\n",
        "!clang  -fopenmp -fopenmp-targets=nvptx64 -Xopenmp-target -march=sm_75 Pi-par-V4.c -o Pi-par-V4\n",
        "\n",
        "!./Pi-par-V4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2-1bt706OrD"
      },
      "source": [
        "# Extra 1- Pi V5.0\n",
        "\n",
        "A seguir, vamos utilizar a GPU para tentar acelerar nosso programa, utilizando:\n",
        "* Construções __teams distribute__ , __parallel for simd__:\n",
        "\n",
        "  `#pragma omp target`    \n",
        "  `#pragma omp teams distribute`   \n",
        "  `for (i=0;i<N;i++) ...`   \n",
        "  `#pragma omp parallel for`   \n",
        "    `for (i=0;i<block_sizeN;i++) ...`\n",
        "     \n",
        "\n",
        "Modifique o programa abaixo, introduzindo a melhoria sugerida.\n",
        "\n",
        "...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWSHoc8h6OrD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6eacbf7-8bc5-4bd1-9f7c-c5c46619c53b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing Pi-par-V5.c\n"
          ]
        }
      ],
      "source": [
        "%%writefile Pi-par-V5.c\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <omp.h>\n",
        "static long num_steps = 100000000;\n",
        "double step;\n",
        "int main ()\n",
        "{\n",
        "   int i;\n",
        "   double x, pi, sum = 0.0;\n",
        "   double start_time, run_time;\n",
        "\n",
        "   step = 1.0 / (double) num_steps;\n",
        "\n",
        "   start_time = omp_get_wtime();\n",
        "   #pragma omp target map(sum)\n",
        "   {\n",
        "     #pragma omp teams distribute parallel for reduction(+:sum) private(x)\n",
        "     for (i = 0; i < num_steps; i++){\n",
        "       x = (i + 0.5) * step;\n",
        "       sum += 4.0 / (1.0 + x * x);\n",
        "     }\n",
        "   }\n",
        "\n",
        "   pi = step * sum;\n",
        "   run_time = omp_get_wtime() - start_time;\n",
        "   printf(\"pi = \\%lf, \\%ld steps, \\%lf secs\\n \",\n",
        "                pi, num_steps, run_time);\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4d9XZkW6OrD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dabe39ef-870d-4fb9-ef19-c01a12376de0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clang-13: \u001b[0;1;35mwarning: \u001b[0m\u001b[1mUnknown CUDA version. cuda.h: CUDA_VERSION=11080. Assuming the latest supported version 10.1 [-Wunknown-cuda-version]\u001b[0m\n",
            "pi = 3.141593, 100000000 steps, 1.741119 secs\n",
            " "
          ]
        }
      ],
      "source": [
        "#%%shell\n",
        "\n",
        "!clang -fopenmp -fopenmp-targets=nvptx64 -Xopenmp-target -march=sm_75 Pi-par-V5.c -o Pi-par-V5\n",
        "\n",
        "!./Pi-par-V5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eVLMZIy6OrD"
      },
      "source": [
        "# Extra 2 - Pi V6.0\n",
        "\n",
        "Juntando tudo isso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_7ct4aL6OrD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc87433c-cd2b-496e-95aa-775c030da5d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing Pi-par-V6.c\n"
          ]
        }
      ],
      "source": [
        "%%writefile Pi-par-V6.c\n",
        "#define MIN(x, y) (((x) < (y)) ? (x) : (y))\n",
        "#include <stdio.h>\n",
        "#include <omp.h>\n",
        "static long num_steps = 100000000;\n",
        "double step;\n",
        "int main ()\n",
        "{\n",
        "   int i;\n",
        "   double x, pi, sum = 0.0;\n",
        "   double start_time, run_time;\n",
        "\n",
        "   step = 1.0 / (double) num_steps;\n",
        "   start_time = omp_get_wtime();\n",
        "   #pragma omp target map(sum)\n",
        "//   #pragma omp teams distribute parallel for simd reduction(+: sum) private(x)\n",
        "   #pragma omp teams distribute parallel for reduction(+: sum) private(x)\n",
        "   for (i=0; i< num_steps; i++){\n",
        "             x = (i + 0.5) * step;\n",
        "             sum += 4.0 / (1.0 + x * x);\n",
        "   }\n",
        "   pi = step * sum;\n",
        "   run_time = omp_get_wtime() - start_time;\n",
        "   printf(\"pi = \\%lf, \\%ld steps, \\%lf secs\\n \",\n",
        "                pi, num_steps, run_time);\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3etWJGlh6OrE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a07a1c7e-6bf2-423b-b8be-c33f2c2b25f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clang-13: \u001b[0;1;35mwarning: \u001b[0m\u001b[1mUnknown CUDA version. cuda.h: CUDA_VERSION=11080. Assuming the latest supported version 10.1 [-Wunknown-cuda-version]\u001b[0m\n",
            "pi = 3.141593, 100000000 steps, 1.714305 secs\n",
            " "
          ]
        }
      ],
      "source": [
        "#%%shell\n",
        "\n",
        "!clang -fopenmp -fopenmp-targets=nvptx64 -Xopenmp-target -march=sm_75 Pi-par-V6.c -o Pi-par-V6\n",
        "\n",
        "!./Pi-par-V6"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}